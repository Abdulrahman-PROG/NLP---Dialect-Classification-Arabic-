{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Important Libraries & Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مازالا كاتمشي لتامازيرت ولا ماعند باباها وجه</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سستيني صافي قلتها ليك البارح</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>معلش يااشرف للاسف الرؤية مش واضحة عند كتير من ...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لبشوف فرحة لاعبين السعودية بقول متأهلين عالنها...</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تشليع الجمعه وبيان فك الإرتباط أقرأ الرساله دى...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118175</th>\n",
       "      <td>صحابى مستغربين ان اختى بتقولى اقلعى الحجاب وان...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118176</th>\n",
       "      <td>لما توقع وما حدا يشوفك صدقني أن الفرحة أكبر من...</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118177</th>\n",
       "      <td>مش من حقن شو السفارة لبيت بيون انا كنت مثلك ما...</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118178</th>\n",
       "      <td>الشعب ماخمل الشعب قرف متل مارضى العيش مع الزبا...</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118179</th>\n",
       "      <td>في يجي يقعد ع خط الكنيسة ويعمل مشاكل ويطلعلي ا...</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118180 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "0            مازالا كاتمشي لتامازيرت ولا ماعند باباها وجه    MA\n",
       "1                            سستيني صافي قلتها ليك البارح    MA\n",
       "2       معلش يااشرف للاسف الرؤية مش واضحة عند كتير من ...    EG\n",
       "3       لبشوف فرحة لاعبين السعودية بقول متأهلين عالنها...    LB\n",
       "4       تشليع الجمعه وبيان فك الإرتباط أقرأ الرساله دى...    SD\n",
       "...                                                   ...   ...\n",
       "118175  صحابى مستغربين ان اختى بتقولى اقلعى الحجاب وان...    EG\n",
       "118176  لما توقع وما حدا يشوفك صدقني أن الفرحة أكبر من...    LB\n",
       "118177  مش من حقن شو السفارة لبيت بيون انا كنت مثلك ما...    LB\n",
       "118178  الشعب ماخمل الشعب قرف متل مارضى العيش مع الزبا...    LB\n",
       "118179  في يجي يقعد ع خط الكنيسة ويعمل مشاكل ويطلعلي ا...    LB\n",
       "\n",
       "[118180 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df = pd.read_csv('preprocessed_train_with_stopwords.csv')\n",
    "Train_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "Train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اخير ليك ما اخير ليك كيفك بس ما من حق تسب السو...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الله يبرد عليها ويجمعها معاه في جنات عدن</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الكلمتين دول فيهم الزيتونة الحقيقة يعني</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سلاام لكل يا حبايبنا جئت اقول مساء الخير واشوف...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>أنا ما بدي تجي وتقول اعذريني مشغول لفتة من بعي...</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29540</th>\n",
       "      <td>بالعكس حبيبى مودى تحويلت سمافرو كرزاز مية فى ا...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29541</th>\n",
       "      <td>طب العهد مين ده الزمالك</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29542</th>\n",
       "      <td>هو موش هايتنحي ولا ايه ياجودعاان راح نيويورك م...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29543</th>\n",
       "      <td>بس انا ماكنتش ف البيت وماشوفتش الحلقة الاعادة ...</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29544</th>\n",
       "      <td>كيفكر فيك شي حد</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29545 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0      اخير ليك ما اخير ليك كيفك بس ما من حق تسب السو...    SD\n",
       "1               الله يبرد عليها ويجمعها معاه في جنات عدن    SD\n",
       "2                الكلمتين دول فيهم الزيتونة الحقيقة يعني    EG\n",
       "3      سلاام لكل يا حبايبنا جئت اقول مساء الخير واشوف...    SD\n",
       "4      أنا ما بدي تجي وتقول اعذريني مشغول لفتة من بعي...    LB\n",
       "...                                                  ...   ...\n",
       "29540  بالعكس حبيبى مودى تحويلت سمافرو كرزاز مية فى ا...    LY\n",
       "29541                            طب العهد مين ده الزمالك    EG\n",
       "29542  هو موش هايتنحي ولا ايه ياجودعاان راح نيويورك م...    EG\n",
       "29543  بس انا ماكنتش ف البيت وماشوفتش الحلقة الاعادة ...    EG\n",
       "29544                                    كيفكر فيك شي حد    MA\n",
       "\n",
       "[29545 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Test_df = pd.read_csv('preprocessed_test_with_stopwords.csv')\n",
    "Test_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "Test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(Train_df['text'].isna().sum())\n",
    "print(Test_df['text'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values in Train_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115084</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115632</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116706</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117618</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text label\n",
       "670     NaN    LY\n",
       "908     NaN    LY\n",
       "1310    NaN    MA\n",
       "1375    NaN    LB\n",
       "1513    NaN    LY\n",
       "...     ...   ...\n",
       "113370  NaN    MA\n",
       "115084  NaN    MA\n",
       "115632  NaN    LY\n",
       "116706  NaN    EG\n",
       "117618  NaN    EG\n",
       "\n",
       "[157 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Rows with NaN values in Train_df:\")\n",
    "Train_df[Train_df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values in Test_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5233</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7721</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15330</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15834</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17530</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17622</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21540</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22416</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23919</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25401</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28034</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28167</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text label\n",
       "616    NaN    EG\n",
       "925    NaN    EG\n",
       "1342   NaN    LB\n",
       "2061   NaN    MA\n",
       "2952   NaN    EG\n",
       "3798   NaN    SD\n",
       "4782   NaN    SD\n",
       "4876   NaN    SD\n",
       "5078   NaN    LY\n",
       "5233   NaN    EG\n",
       "6178   NaN    EG\n",
       "6466   NaN    EG\n",
       "7460   NaN    EG\n",
       "7721   NaN    EG\n",
       "11595  NaN    LY\n",
       "12548  NaN    MA\n",
       "13174  NaN    MA\n",
       "13346  NaN    SD\n",
       "15051  NaN    SD\n",
       "15330  NaN    EG\n",
       "15834  NaN    MA\n",
       "17530  NaN    LB\n",
       "17622  NaN    LY\n",
       "20943  NaN    EG\n",
       "20997  NaN    MA\n",
       "21540  NaN    LY\n",
       "22184  NaN    LY\n",
       "22416  NaN    LY\n",
       "23180  NaN    LB\n",
       "23919  NaN    SD\n",
       "25194  NaN    EG\n",
       "25401  NaN    MA\n",
       "28034  NaN    EG\n",
       "28167  NaN    EG\n",
       "28219  NaN    LY\n",
       "28240  NaN    EG\n",
       "28335  NaN    SD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Rows with NaN values in Test_df:\")\n",
    "Test_df[Test_df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the 'text' column of Train_df\n",
    "Train_df = Train_df.dropna(subset=['text'])\n",
    "\n",
    "# Drop rows with NaN values in the 'text' column of Test_df\n",
    "Test_df = Test_df.dropna(subset=['text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(use_idf=True)\n",
    "X_train_counts = tfidf.fit_transform(Train_df['text'])\n",
    "X_test_counts = tfidf.transform(Test_df['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10104   283   557   162   407]\n",
      " [  260  4727   309    89   135]\n",
      " [  531   341  5923   263   235]\n",
      " [  163   112   212  1707   108]\n",
      " [  409   153   251    66  2001]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.88      0.88      0.88     11513\n",
      "          LB       0.84      0.86      0.85      5520\n",
      "          LY       0.82      0.81      0.81      7293\n",
      "          MA       0.75      0.74      0.74      2302\n",
      "          SD       0.69      0.69      0.69      2880\n",
      "\n",
      "    accuracy                           0.83     29508\n",
      "   macro avg       0.80      0.80      0.80     29508\n",
      "weighted avg       0.83      0.83      0.83     29508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_balance = LogisticRegression(random_state=42,class_weight='balanced',solver='newton-cg',C=10).fit(X_train_counts, Train_df['label'])\n",
    "y_pred=clf_balance.predict(X_test_counts)\n",
    "print(confusion_matrix(Test_df['label'],y_pred))\n",
    "print(classification_report(Test_df['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8903  576 1315  198  521]\n",
      " [ 804 3668  721  142  185]\n",
      " [1568  680 4418  350  277]\n",
      " [ 410  215  526 1020  131]\n",
      " [ 899  279  477  107 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.71      0.77      0.74     11513\n",
      "          LB       0.68      0.66      0.67      5520\n",
      "          LY       0.59      0.61      0.60      7293\n",
      "          MA       0.56      0.44      0.50      2302\n",
      "          SD       0.50      0.39      0.44      2880\n",
      "\n",
      "    accuracy                           0.65     29508\n",
      "   macro avg       0.61      0.57      0.59     29508\n",
      "weighted avg       0.64      0.65      0.64     29508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree= dtree.fit(X_train_counts,Train_df['label'])\n",
    "predictions = dtree.predict(X_test_counts)\n",
    "print(confusion_matrix(Test_df['label'], predictions))\n",
    "print(classification_report(Test_df['label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0da/boda/Nlp_Project/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/b0da/boda/Nlp_Project/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/b0da/boda/Nlp_Project/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/b0da/boda/Nlp_Project/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10392   259   575    66   221]\n",
      " [  320  4674   369    61    96]\n",
      " [  698   320  5973   160   142]\n",
      " [  241   120   298  1573    70]\n",
      " [  556   155   311    48  1810]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          EG       0.85      0.90      0.88     11513\n",
      "          LB       0.85      0.85      0.85      5520\n",
      "          LY       0.79      0.82      0.81      7293\n",
      "          MA       0.82      0.68      0.75      2302\n",
      "          SD       0.77      0.63      0.69      2880\n",
      "\n",
      "    accuracy                           0.83     29508\n",
      "   macro avg       0.82      0.78      0.79     29508\n",
      "weighted avg       0.83      0.83      0.83     29508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression()))\n",
    "level0.append(('dtree', DecisionTreeClassifier()))\n",
    "level1 =LogisticRegression()\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=3)\n",
    "model.fit(X_train_counts,Train_df['label'])\n",
    "yhat = model.predict(X_test_counts)\n",
    "print(confusion_matrix(Test_df['label'],yhat))\n",
    "\n",
    "print(classification_report(Test_df['label'],yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(clf_balance, 'logistic_regression_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload the model and test it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label for 'يازول' is: SD\n"
     ]
    }
   ],
   "source": [
    "import tnkeeh as tn\n",
    "import re\n",
    "\n",
    "def predict_label(text):\n",
    "\n",
    "    # text preprocessing\n",
    "    cleander = tn.Tnkeeh(remove_diacritics=True,\n",
    "                     remove_html_elements=True,\n",
    "                     remove_twitter_meta=True,\n",
    "                     remove_links=True,\n",
    "                     remove_english=True,\n",
    "                     remove_repeated_chars=True,\n",
    "                     remove_long_words=True,\n",
    "                     normalize=True\n",
    "                     )\n",
    "\n",
    "    text = cleander.clean_raw_text(text)\n",
    "    text = text[0]\n",
    "\n",
    "    text = text.replace(r'[0-9٠-٩]', '')\n",
    "    text = text.replace(\"؟\", \"\")\n",
    "    text = text.replace(\"@\", \"\")\n",
    "    text = text.replace(\"_\", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    arabic_punctuation_pattern = r'[^\\w\\s\\u0621-\\u063A\\u0641-\\u064A]'\n",
    "    text = re.sub(arabic_punctuation_pattern,'',text)\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Load the model and the vectorizer\n",
    "    clf_balance = joblib.load('logistic_regression_model.pkl')\n",
    "    tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "    # Transform the input text\n",
    "    text_transformed = tfidf.transform([text])\n",
    "\n",
    "    # Predict the label\n",
    "    predicted_label = clf_balance.predict(text_transformed)\n",
    "\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Example prediction\n",
    "text = \"يازول\"\n",
    "predicted_label = predict_label(text)\n",
    "print(f\"The predicted label for '{text}' is: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
